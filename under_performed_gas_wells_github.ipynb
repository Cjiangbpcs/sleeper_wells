{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal: identify under performed gas wells using RailRoad Commision of Texas public data request\n",
    "methodology: SPE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.tools import plotting\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy\n",
    "import glob\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "#query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\"\n",
    "cursor = con.cursor()\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "cursor = con.cursor()\n",
    "string = \"DROP TABLE up5_adj_prod\"\n",
    "cursor.execute(string)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "cursor = con.cursor()\n",
    "string = \"DROP TABLE up5_well_frac_adj\"\n",
    "cursor.execute(string)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellbore locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT API, WB_WGS84_LATITUDE, WB_WGS84_LONGITUDE FROM WellBore_Location\"\n",
    "wb_location = pd.read_sql(query,con)\n",
    "print('wb_location:',list(wb_location.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_location['WB_WGS84_LATITUDE'] = wb_location['WB_WGS84_LATITUDE'].map(lambda x: str(x)[:-1]).astype('float64')/1e6\n",
    "wb_location['WB_WGS84_LONGITUDE'] = wb_location['WB_WGS84_LONGITUDE'].map(lambda x: str(x)[:-1]).astype('float64')/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_location['API_COUNTY_CODE'] = wb_location['API'].map(lambda x: str(x)[:3])\n",
    "wb_location['API_UNIQUE_NO'] = wb_location['API'].map(lambda x: str(x)[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_location.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM OG_WELL_COMPLETION\"\n",
    "OG_WELL_COMPLETION = pd.read_sql(query,con)\n",
    "print('OG_WELL_COMPLETION:',list(OG_WELL_COMPLETION.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_WELL_COMPLETION.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gas production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT OIL_GAS_CODE, DISTRICT_NO, FIELD_NO, CYCLE_YEAR_MONTH, GAS_WELL_NO, CYCLE_YEAR_MONTH, LEASE_NO, COUNTY_NO, DISTRICT_NO, OPERATOR_NO, LEASE_NAME, CNTY_LSE_GAS_PROD_VOL FROM OG_COUNTY_LEASE_CYCLE\"\n",
    "OG_COUNTY_LEASE_CYCLE = pd.read_sql(query,con)\n",
    "print('OG_COUNTY_LEASE_CYCLE:',list(OG_COUNTY_LEASE_CYCLE.columns))\n",
    "OG_COUNTY_LEASE_CYCLE.to_csv('gas_cnty_lse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_COUNTY_LEASE_CYCLE = pd.read_csv('gas_cnty_lse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_WELL_COMPLETION.apply(lambda col:pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_WELL_COMPLETION['DISTRICT_NO'] = OG_WELL_COMPLETION['DISTRICT_NO'].astype('int64')\n",
    "OG_WELL_COMPLETION['LEASE_NO'] = OG_WELL_COMPLETION['LEASE_NO'].map(lambda x: re.sub('[a-zA-Z]', '', x))\n",
    "OG_WELL_COMPLETION['LEASE_NO'] = OG_WELL_COMPLETION['LEASE_NO'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_og_county_lease_cycle = pd.merge(left = OG_COUNTY_LEASE_CYCLE, right = OG_WELL_COMPLETION, on=['OIL_GAS_CODE', 'DISTRICT_NO', 'LEASE_NO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_og_county_lease_cycle.columns)\n",
    "new_df = pd.merge(left = new_og_county_lease_cycle, right = wb_location, on =['API_COUNTY_CODE','API_UNIQUE_NO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g = new_df.loc[new_df['OIL_GAS_CODE'] == 'G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s = new_df_g[['API','CYCLE_YEAR_MONTH','DISTRICT_NO','COUNTY_NO','FIELD_NO','OPERATOR_NO','WELL_NO','LEASE_NO','WB_WGS84_LATITUDE','WB_WGS84_LONGITUDE','CNTY_LSE_GAS_PROD_VOL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_df_g_s.API.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s.to_csv('gas_well_prod.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rank wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s = pd.read_csv('gas_well_prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s['WELL_NO'] = new_df_g_s['WELL_NO'].astype('|S')\n",
    "new_df_g_s.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEASE_list = new_df_g_s.LEASE_NO.unique()\n",
    "print('total # of leases:', np.shape(LEASE_list))\n",
    "print('total # of API:', np.shape(new_df_g_s.API.unique()))\n",
    "lease = random.randint(0, np.shape(LEASE_list)[0])\n",
    "df_lease = new_df_g_s[new_df_g_s['LEASE_NO'] == LEASE_list[lease]]\n",
    "print('lease:', df_lease.LEASE_NO.unique())\n",
    "print('api:', df_lease.API.unique())\n",
    "print('district:',df_lease.DISTRICT_NO.unique())\n",
    "print('county:',df_lease.COUNTY_NO.unique())\n",
    "print('field:',df_lease.FIELD_NO.unique())\n",
    "print('operator:',df_lease.OPERATOR_NO.unique())\n",
    "print('well:',df_lease.WELL_NO.unique())\n",
    "print('lat:',df_lease.WB_WGS84_LATITUDE.unique())\n",
    "print('lon:',df_lease.WB_WGS84_LONGITUDE.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select gas wells that have reporting dates between 199401 and 201312\n",
    "def cl(df, LEASE_list):\n",
    "    df_TIME_lease = []\n",
    "    df_TIME_min = []\n",
    "    df_TIME_max = []\n",
    "    df_TIME = pd.DataFrame(columns=['LEASE_NO', 'MIN_TIME', 'MAX_TIME'])\n",
    "    for ls in range(len(LEASE_list)):\n",
    "        df_ls = df.loc[df['LEASE_NO'] == LEASE_list[ls], ['LEASE_NO', 'API', 'CYCLE_YEAR_MONTH', 'WB_WGS84_LATITUDE','WB_WGS84_LONGITUDE','CNTY_LSE_GAS_PROD_VOL']]\n",
    "        df_TIME_lease.append(LEASE_list[ls])\n",
    "        df_TIME_min.append(df_ls.CYCLE_YEAR_MONTH.min())\n",
    "        df_TIME_max.append(df_ls.CYCLE_YEAR_MONTH.max())\n",
    "    df_TIME['LEASE_NO'] = df_TIME_lease\n",
    "    df_TIME['MIN_TIME'] = df_TIME_min\n",
    "    df_TIME['MAX_TIME'] = df_TIME_max \n",
    "    return df_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###separate wells to four different parts\n",
    "#new_df_g_s_p1 = cl(new_df_g_s, LEASE_list[:50000])\n",
    "#new_df_g_s_p1 = new_df_g_s_p1.dropna()\n",
    "#new_df_g_s_p2 = cl(new_df_g_s, LEASE_list[50000:100000])\n",
    "#new_df_g_s_p2 = new_df_g_s_p2.dropna()\n",
    "#new_df_g_s_p3 = cl(new_df_g_s, LEASE_list[100000:150000])\n",
    "#new_df_g_s_p3 = new_df_g_s_p3.dropna()\n",
    "#new_df_g_s_p4 = cl(new_df_g_s, LEASE_list[150000:])\n",
    "#new_df_g_s_p4 = new_df_g_s_p4.dropna()\n",
    "#new_df_g_s_p1.to_csv('gas_well_time_p1.csv')\n",
    "#new_df_g_s_p2.to_csv('gas_well_time_p2.csv')\n",
    "#new_df_g_s_p3.to_csv('gas_well_time_p3.csv')\n",
    "#new_df_g_s_p4.to_csv('gas_well_time_p4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_g_s_p1 = pd.read_csv('gas_well_time_p1.csv')\n",
    "new_df_g_s_p2 = pd.read_csv('gas_well_time_p2.csv')\n",
    "new_df_g_s_p3 = pd.read_csv('gas_well_time_p3.csv')\n",
    "new_df_g_s_p4 = pd.read_csv('gas_well_time_p4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove records outside of 199401-201312\n",
    "new_df_g_s_p14 = pd.concat([new_df_g_s_p1, new_df_g_s_p2, new_df_g_s_p3, new_df_g_s_p4], ignore_index=True)\n",
    "LEASE_list_199401_201312 = list(new_df_g_s_p14.loc[(new_df_g_s_p14['MIN_TIME'] <= 199401) & (new_df_g_s_p14['MAX_TIME'] >= 201312), 'LEASE_NO'])\n",
    "new_df_199401_201312 = new_df_g_s.loc[new_df_g_s['LEASE_NO'].isin(LEASE_list_199401_201312)]\n",
    "new_df_199401_201312 = new_df_199401_201312.loc[(new_df_199401_201312['CYCLE_YEAR_MONTH'] >=199401) & (new_df_199401_201312['CYCLE_YEAR_MONTH'] <= 201312)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select gas wells that not all zeros \n",
    "def cl_0(df, LEASE_list):\n",
    "    lease_list = []\n",
    "    for ls in range(len(LEASE_list)):\n",
    "        df_ls = df.loc[df['LEASE_NO'] == LEASE_list[ls]]\n",
    "        if df_ls[df_ls.CNTY_LSE_GAS_PROD_VOL !=0].empty:\n",
    "            lease_list.append(LEASE_list[ls])\n",
    "    return lease_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###separate wells into four different parts\n",
    "LEASE_list_20y_x = cl_0(new_df_199401_201312, LEASE_list_199401_201312[:10000])\n",
    "LEASE_list_20y_x1 = cl_0(new_df_199401_201312, LEASE_list_199401_201312[10000:25000])\n",
    "LEASE_list_20y_x2 = cl_0(new_df_199401_201312, LEASE_list_199401_201312[25000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lease_list_20y_x = LEASE_list_20y_x + LEASE_list_20y_x1 + LEASE_list_20y_x2\n",
    "new_df_20y = new_df_199401_201312.loc[~new_df_199401_201312['LEASE_NO'].isin(lease_list_20y_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = '%Y%m'\n",
    "new_df_20y['Datetime'] = pd.to_datetime(new_df_20y['CYCLE_YEAR_MONTH'], format=format)\n",
    "new_df_20y = new_df_20y.set_index(pd.DatetimeIndex(new_df_20y['Datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "#new_df_20y = new_df_20y[np.abs(new_df_20y.CNTY_LSE_GAS_PROD_VOL - new_df_20y.CNTY_LSE_GAS_PROD_VOL.mean()) <= (3*new_df_20y.CNTY_LSE_GAS_PROD_VOL.std())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df_20y.to_csv('new_df_20y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_20y = pd.read_csv('new_df_20y.csv')\n",
    "new_df_20y = new_df_20y.set_index(pd.DatetimeIndex(new_df_20y['Datetime']))\n",
    "new_df_20y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEASE_list_20y = list(new_df_20y.LEASE_NO.unique())\n",
    "np.shape(LEASE_list_20y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_lease = new_df_20y[['API', 'LEASE_NO']].drop_duplicates().reset_index(drop=True)\n",
    "api_lease_locations = new_df_20y[['API','LEASE_NO','WB_WGS84_LONGITUDE','WB_WGS84_LATITUDE']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_lease_locations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify adjacents wells for each gas well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify locations for above leases\n",
    "def loc(df):\n",
    "    adj_ls = {}\n",
    "    ls_list = list(df.LEASE_NO.unique())\n",
    "    for ls in range(0, len(ls_list)):\n",
    "        adj_ls[ls_list[ls]] = [df.loc[df['LEASE_NO'] == ls_list[ls]].WB_WGS84_LATITUDE.iloc[1], df.loc[df['LEASE_NO'] == ls_list[ls]].WB_WGS84_LONGITUDE.iloc[1]]\n",
    "    return adj_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_20y_latlon = loc(new_df_20y)\n",
    "new_df_20y_latlon_df = pd.DataFrame.from_dict(new_df_20y_latlon, orient=\"index\", columns=['lat','lon'])\n",
    "#new_df_20y_latlon_df.to_csv('new_df_20y_latlon_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_20y_latlon_df.to_csv('new_df_20y_latlon_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify adjacents wells for each well within dst\n",
    "def adj_well(df_dist, dst, ls_list):\n",
    "    adj_ls_ls = {}\n",
    "    for ls in range(df_dist.shape[0]):\n",
    "        adjj = list(df_dist.loc[ls] < dst)\n",
    "        adj_ls_ls[ls_list[ls]] = [ls_list[i] for i, x in enumerate(adjj) if x]\n",
    "    return adj_ls_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dst = 0.02degree ~= 6000 feet radius\n",
    "#new_df_20y_latlon_df = pd.read_csv('new_df_20y_latlon_df.csv')\n",
    "dist = pdist(new_df_20y_latlon_df[['lat', 'lon']], 'euclidean')\n",
    "df_dist = pd.DataFrame(squareform(dist))\n",
    "adj_well_dic = adj_well(df_dist, 0.03, list(new_df_20y_latlon_df.index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_well_dic[131078]\n",
    "a = new_df_20y_latlon_df[new_df_20y_latlon_df.index == 140808]\n",
    "b = new_df_20y_latlon_df[new_df_20y_latlon_df.index == 137166]\n",
    "np.linalg.norm(np.array(a.lat,a.lon)-np.array(b.lat,b.lon))\n",
    "#scipy.spatial.distance.euclidean(np.array(a.lat,a.lon),np.array(b.lat,b.lon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify under-performed gas wells: cumulative prod indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20year, 10year, 5year, 4year, 2year, 1year\n",
    "#LEASE_NO, start_year, end_year, interval_year, cumulative_prod, normalized_prod\n",
    "def ana_cumulative(df, ls_list):\n",
    "    df_output = {}\n",
    "    for ls in range(0, len(ls_list)):\n",
    "        df_ls = df.loc[df['LEASE_NO'] == ls_list[ls], 'CNTY_LSE_GAS_PROD_VOL']\n",
    "        df_output[ls_list[ls]] = np.sum(df_ls)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ana_int_yr(new_df_20y, yr1, yr2, LEASE_list_20y, adj_well_dic):\n",
    "    for i in range(len(yr1)):\n",
    "        new_df_20y_int = new_df_20y[(new_df_20y.index.year >= yr1[i]) & (new_df_20y.index.year <= yr2[i])]\n",
    "        ana_20y = ana_cumulative(new_df_20y_int, LEASE_list_20y)\n",
    "        ana_20y_df = pd.DataFrame.from_dict(ana_20y, orient=\"index\")\n",
    "        ana_20y_df = ana_20y_df.rename(columns={0:'cumulative_prod'})\n",
    "        lease_list = list(ana_20y_df.index.unique())\n",
    "        p_list = []\n",
    "        for ls in range(len(lease_list)):\n",
    "            ana_20y_df_adj = ana_20y_df.loc[adj_well_dic[lease_list[ls]], 'cumulative_prod']\n",
    "            p_list.append(pd.qcut(ana_20y_df_adj,100, labels=False, duplicates='drop')[lease_list[ls]])\n",
    "        ana_20y_df['percentile'] = p_list\n",
    "        ana_20y_df['start_year'] = yr1[i]\n",
    "        ana_20y_df['end_year'] = yr2[i]\n",
    "        ana_20y_df['interval_year'] = yr2[i] - yr1[i] + 1\n",
    "        ana_20y_df.to_csv('ana_20y_df_' + str(yr1[i]) + '_' + str(yr2[i]) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20year\n",
    "yr1 = [1994]\n",
    "yr2 = [2013]\n",
    "ana_int_yr(new_df_20y_nolier, yr1, yr2, LEASE_list_20y, adj_well_dic)\n",
    "#10year\n",
    "yr1 = [i for i in range(1994, 2013, 10)]\n",
    "yr2 = [i for i in range(2003, 2022, 10)]\n",
    "ana_int_yr(new_df_20y_nolier, yr1, yr2, LEASE_list_20y, adj_well_dic)\n",
    "#5year\n",
    "yr1 = [i for i in range(1994, 2014, 5)]\n",
    "yr2 = [i for i in range(1998, 2018, 5)]\n",
    "ana_int_yr(new_df_20y_nolier, yr1, yr2, LEASE_list_20y, adj_well_dic)\n",
    "#4year\n",
    "yr1 = [i for i in range(1994, 2014, 4)]\n",
    "yr2 = [i for i in range(1997, 2017, 4)]\n",
    "ana_int_yr(new_df_20y_nolier, yr1, yr2, LEASE_list_20y, adj_well_dic)\n",
    "#2year\n",
    "yr1 = [i for i in range(1994, 2014, 2)]\n",
    "yr2 = [i for i in range(1995, 2015, 2)]\n",
    "ana_int_yr(new_df_20y_nolier, yr1, yr2, LEASE_list_20y, adj_well_dic)\n",
    "#1year\n",
    "yr1 = [i for i in range(1994, 2014, 1)]\n",
    "yr2 = [i for i in range(1994, 2014, 1)]\n",
    "ana_int_yr(new_df_20y, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify under-performed gas wells: normalized prod indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_prod = new_df_20y.groupby('LEASE_NO').apply(lambda x: x.CNTY_LSE_GAS_PROD_VOL.resample('12m').mean())/12\n",
    "norm_prod_t = norm_prod.T\n",
    "def ana_normalized(df, ls_list):\n",
    "    df_output = {}\n",
    "    for ls in range(0, len(ls_list)):\n",
    "        df_ls = df.loc[:, ls_list[ls]]\n",
    "        df_output[ls_list[ls]] = np.mean(df_ls)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ana_int_yr_normalized(df, yr1, yr2, ls_list, adj_well_dic):\n",
    "    for i in range(len(yr1)):\n",
    "        df_int = df.loc[(df.index.year>=yr1[i]) & (df.index.year>=yr2[i])]\n",
    "        ana_20y = ana_normalized(df_int, ls_list)\n",
    "        ana_20y_df = pd.DataFrame.from_dict(ana_20y, orient=\"index\")\n",
    "        ana_20y_df = ana_20y_df.rename(columns={0:'normalized_prod'})\n",
    "        lease_list = list(ana_20y_df.index.unique())\n",
    "        p_list = []\n",
    "        for ls in range(len(lease_list)):\n",
    "            ana_20y_df_adj = ana_20y_df.loc[adj_well_dic[lease_list[ls]], 'normalized_prod']\n",
    "            p_list.append(pd.qcut(ana_20y_df_adj,100, labels=False, duplicates='drop')[lease_list[ls]])\n",
    "        ana_20y_df['percentile'] = p_list\n",
    "        ana_20y_df['start_year'] = yr1[i]\n",
    "        ana_20y_df['end_year'] = yr2[i]\n",
    "        ana_20y_df['interval_year'] = yr2[i] - yr1[i] + 1\n",
    "        ana_20y_df.to_csv('ana_20y_normalized_' + str(yr1[i]) + '_' + str(yr2[i]) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20year\n",
    "yr1 = [1994]\n",
    "yr2 = [2013]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10year\n",
    "yr1 = [i for i in range(1994, 2013, 10)]\n",
    "yr2 = [i for i in range(2003, 2022, 10)]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5year\n",
    "yr1 = [i for i in range(1994, 2014, 5)]\n",
    "yr2 = [i for i in range(1998, 2018, 5)]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4year\n",
    "yr1 = [i for i in range(1994, 2014, 4)]\n",
    "yr2 = [i for i in range(1997, 2017, 4)]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2year\n",
    "yr1 = [i for i in range(1994, 2014, 2)]\n",
    "yr2 = [i for i in range(1995, 2015, 2)]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1year\n",
    "yr1 = [i for i in range(1994, 2014, 1)]\n",
    "yr2 = [i for i in range(1994, 2014, 1)]\n",
    "ana_int_yr_normalized(norm_prod_t, yr1, yr2, LEASE_list_20y, adj_well_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative prod\n",
    "allFiles = glob.glob('./' + \"ana_20y_df_*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'lease_no','percentile':'cp_p_'+file_[-13:-4],'cumulative_prod':'cp_'+file_[-13:-4], 'start_year':'cp_y0_'+file_[-13:-4], 'end_year':'cp_y1_'+file_[-13:-4],'interval_year':'cp_yi_'+file_[-13:-4]})\n",
    "    df = df.set_index('lease_no')\n",
    "    list_.append(df)\n",
    "frm = pd.concat([i for i in list_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_col = [col for col in frm if col.startswith('cp_p_')]\n",
    "frm_ana = frm[filter_col]\n",
    "lease_list = list(frm_ana.index.unique())\n",
    "#for ll in range(len(lease_list)):\n",
    "#    frm.loc[lease_list[ll], 'cp_lt50'] = sum(frm_ana.iloc[ll] <= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized prod\n",
    "allFiles = glob.glob('./' + \"ana_20y_normalized_*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'lease_no','percentile':'np_p_'+file_[-13:-4],'cumulative_prod':'np_'+file_[-13:-4], 'start_year':'np_y0_'+file_[-13:-4], 'end_year':'np_y1_'+file_[-13:-4],'interval_year':'np_yi_'+file_[-13:-4]})\n",
    "    df = df.set_index('lease_no')\n",
    "    list_.append(df)\n",
    "frm_norm = pd.concat([i for i in list_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_col = [col for col in frm_norm if col.startswith('np_p_')]\n",
    "frm_ana_norm = frm_norm[filter_col]\n",
    "lease_list_norm = list(frm_ana_norm.index.unique())\n",
    "#for ll in range(len(lease_list_norm)):\n",
    "#    frm_norm.loc[lease_list_norm[ll], 'np_lt50'] = sum(frm_ana_norm.iloc[ll] <= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = frm_ana_norm.join(frm)\n",
    "#metrics['cp_np'] = metrics['cp_lt50'] + metrics['np_lt50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = frm_ana_norm.join(frm_ana)\n",
    "metrics= metrics.stack().reset_index()\n",
    "prod_metrics = metrics[['lease_no', 0]]\n",
    "prod_metrics = prod_metrics.rename(columns = {0:'percentile', 'lease_no':'lease_no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_well = metrics['cp_np'].nlargest(20).index\n",
    "op_well = list(set(metrics.index) - set(up_well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw = random.randint(0, len(up_well))\n",
    "new_df_20y.loc[new_df_20y['LEASE_NO'] == up_well[uw], 'CNTY_LSE_GAS_PROD_VOL'].plot()\n",
    "adjj = adj_well_dic[up_well[uw]]\n",
    "ad = random.randint(0, len(adjj))\n",
    "new_df_20y.loc[new_df_20y['LEASE_NO'] == adjj[ad], 'CNTY_LSE_GAS_PROD_VOL'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw = random.randint(0, len(up_well))\n",
    "norm_prod_t.loc[:, up_well[uw]].plot()\n",
    "adjj = adj_well_dic[up_well[uw]]\n",
    "ad = random.randint(0, len(adjj))\n",
    "norm_prod_t.loc[:,adjj[ad]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_20y.loc[~new_df_20y['LEASE_NO'].isin(up_well), 'CNTY_LSE_GAS_PROD_VOL'].plot(ylim=(0, 7e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_prod_t.head(10)\n",
    "norm_prod_t.loc[:, up_well].plot(legend=None, ylim=(0, 2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_prod_t.loc[:, op_well[:50]].plot(legend=None, ylim=(0, 2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_well[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# push data to sql server as schemas and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 tables: 1.prod_metrics, 2.monthly_prod, 3.cum_prod, 4.norm_prod, 5.adjacents, 6.locations\n",
    "#1.prod_metrics\n",
    "##metrics['lease_no'] = metrics.index\n",
    "##metrics_ls = list(metrics.lease_no.unique())\n",
    "##prod_metrics = metrics[['lease_no', 'cp_np']]\n",
    "##prod_metrics = prod_metrics.rename(columns = {'cp_np':'cp_np_counts_84', 'lease_no':'lease_no'})\n",
    "##prod_metrics.cp_np_counts_84 = prod_metrics.cp_np_counts_84.astype('int64')\n",
    "##prod_metrics.index = range(prod_metrics.shape[0])\n",
    "##prod_metrics.to_csv('prod_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.prod_metrics\n",
    "prod_metrics.to_csv('prod_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_metrics = pd.read_csv('prod_metrics.csv')\n",
    "metrics_ls = list(prod_metrics.lease_no.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.monthly_prod\n",
    "monthly_prod = new_df_20y.loc[new_df_20y['LEASE_NO'].isin(metrics_ls), ['LEASE_NO','CYCLE_YEAR_MONTH','CNTY_LSE_GAS_PROD_VOL']]\n",
    "monthly_prod = monthly_prod.rename(columns = {'LEASE_NO': 'lease_no', 'CYCLE_YEAR_MONTH':'date', 'CNTY_LSE_GAS_PROD_VOL': 'monthly_prod'})\n",
    "monthly_prod.index = range(monthly_prod.shape[0])\n",
    "monthly_prod = monthly_prod[np.abs(monthly_prod.monthly_prod - monthly_prod.monthly_prod.mean()) <= (3*monthly_prod.monthly_prod.std())]\n",
    "monthly_prod.to_csv('monthly_prod.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.cumulative prod: new_df_20y\n",
    "#5 years only\n",
    "yr1 = [i for i in range(1994, 2014, 5)]\n",
    "yr2 = [i for i in range(1998, 2018, 5)]\n",
    "def ana_int_yr_5ysum(new_df_20y, yr1, yr2, LEASE_list_20y):\n",
    "    for i in range(len(yr1)):\n",
    "        new_df_20y_int = new_df_20y[(new_df_20y.index.year >= yr1[i]) & (new_df_20y.index.year <= yr2[i])]\n",
    "        ana_20y = ana_cumulative(new_df_20y_int, LEASE_list_20y)\n",
    "        ana_20y_df = pd.DataFrame.from_dict(ana_20y, orient=\"index\")\n",
    "        ana_20y_df = ana_20y_df.rename(columns={0:'cumulative_prod'})\n",
    "        ana_20y_df['start_year'] = yr1[i]\n",
    "        ana_20y_df['end_year'] = yr2[i]\n",
    "        ana_20y_df.to_csv('ana_20y_cp_5ysum_' + str(yr1[i]) + '_' + str(yr2[i]) + '.csv')\n",
    "ana_int_yr_5ysum(new_df_20y, yr1, yr2, LEASE_list_20y)\n",
    "\n",
    "# cumulative prod\n",
    "allFiles = glob.glob('./' + \"ana_20y_cp_*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'lease_no','cumulative_prod':'cp_'+file_[-13:-4], 'start_year':'y0_'+file_[-13:-4], 'end_year':'y1_'+file_[-13:-4]})\n",
    "    df = df.set_index('lease_no')\n",
    "    list_.append(df)\n",
    "frm = pd.concat([i for i in list_], axis=1)\n",
    "filter_col = [col for col in frm if col.startswith('cp_')]\n",
    "prod_cumul = frm[filter_col]\n",
    "prod_cumul = prod_cumul.rename(columns = {'cp_1994_1998':'199606', 'cp_1999_2003':'200106', 'cp_2004_2008':'200606','cp_2009_2013':'201106'})\n",
    "prod_cumul = prod_cumul.stack().reset_index()\n",
    "prod_cumul = prod_cumul.rename(columns={'level_1':'date', 0:'cp'})\n",
    "prod_cumul.to_csv('prod_cumul.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.normalized prod: norm_prod_t\n",
    "#5 years only\n",
    "yr1 = [i for i in range(1994, 2014, 5)]\n",
    "yr2 = [i for i in range(1998, 2018, 5)]\n",
    "def ana_int_yr_normalized_5ysum(df, yr1, yr2, ls_list):\n",
    "    for i in range(len(yr1)):\n",
    "        df_int = df.loc[(df.index.year>=yr1[i]) & (df.index.year>=yr2[i])]\n",
    "        ana_20y = ana_normalized(df_int, ls_list)\n",
    "        ana_20y_df = pd.DataFrame.from_dict(ana_20y, orient=\"index\")\n",
    "        ana_20y_df = ana_20y_df.rename(columns={0:'normalized_prod'})\n",
    "        ana_20y_df['start_year'] = yr1[i]\n",
    "        ana_20y_df['end_year'] = yr2[i]\n",
    "        ana_20y_df.to_csv('ana_20y_np_5ysum_' + str(yr1[i]) + '_' + str(yr2[i]) + '.csv')\n",
    "ana_int_yr_normalized_5ysum(norm_prod_t, yr1, yr2, LEASE_list_20y)\n",
    "# normalized prod\n",
    "allFiles = glob.glob('./' + \"ana_20y_np_*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    df = df.rename(columns = {'Unnamed: 0': 'lease_no','normalized_prod':'np_'+file_[-13:-4], 'start_year':'y0_'+file_[-13:-4], 'end_year':'y1_'+file_[-13:-4]})\n",
    "    df = df.set_index('lease_no')\n",
    "    list_.append(df)\n",
    "frm = pd.concat([i for i in list_], axis=1)\n",
    "filter_col = [col for col in frm if col.startswith('np_')]\n",
    "prod_norm = frm[filter_col]\n",
    "prod_norm = prod_norm.rename(columns = {'np_1994_1998':'199606', 'np_1999_2003':'200106', 'np_2004_2008':'200606','np_2009_2013':'201106'})\n",
    "prod_norm = prod_norm.stack().reset_index()\n",
    "prod_norm = prod_norm.rename(columns={'level_1':'date', 0:'np'})\n",
    "prod_norm.to_csv('prod_norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.adjacents\n",
    "adjacents = pd.DataFrame()\n",
    "adjacents['lease_no'] = adj_well_dic.keys()\n",
    "adjacents['adjacents'] = adjacents['lease_no'].map(adj_well_dic)\n",
    "adj_wells = (adjacents['adjacents'].apply(lambda x: pd.Series(x)).stack().reset_index(level=1, drop=True).to_frame('adjacents').join(adjacents[['lease_no']], how='right'))\n",
    "adj_wells['adjacents'] = adj_wells['adjacents'].astype('int')\n",
    "adj_wells.to_csv('adj_wells.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.locations\n",
    "locations_wells = new_df_20y_latlon_df\n",
    "locations_wells['lease_no'] = locations_wells.index\n",
    "locations_wells = locations_wells.reset_index()\n",
    "locations_wells = locations_wells.drop(columns='index')\n",
    "locations_wells.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "cursor = con.cursor()\n",
    "string = \"DROP TABLE locations_wells\"\n",
    "cursor.execute(string)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_metrics = pd.read_csv('prod_metrics.csv')\n",
    "adj_wells = pd.read_csv('adj_wells.csv')\n",
    "monthly_prod = pd.read_csv('monthly_prod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "prod_cumul = pd.read_csv('prod_cumul.csv')\n",
    "prod_cumul['date'] = prod_cumul['date'].apply(lambda x: datetime.datetime.strptime(str(x), '%Y%m'))\n",
    "print(prod_cumul.dtypes)\n",
    "prod_cumul.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_norm = pd.read_csv('prod_norm.csv')\n",
    "prod_norm['date'] = prod_norm['date'].apply(lambda x: datetime.datetime.strptime(str(x), '%Y%m'))\n",
    "print(prod_norm.dtypes)\n",
    "prod_norm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = urllib.parse.quote_plus(r'DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "engine = create_engine(conn_str)\n",
    "#prod_metrics.to_sql(name='well_metrics',con=engine, if_exists = 'append', chunksize=1000, index=False, schema=\"dbo\")\n",
    "prod_norm.to_sql(name='prod_norm',con=engine, if_exists = 'replace', chunksize=500, index=False, schema=\"dbo\")\n",
    "#prod_cumul.to_sql(name='prod_cumul',con=engine, if_exists = 'replace', chunksize=500, index=False, schema=\"dbo\")\n",
    "#adj_wells.to_sql(name='adj_wells',con=engine, if_exists = 'replace', chunksize=1000, index=False, schema=\"dbo\")\n",
    "#locations_wells.to_sql(name='well_locations',con=engine, if_exists = 'append', chunksize=500, index=False, schema=\"dbo\")\n",
    "#monthly_prod.to_sql(name='monthly_prod',con=engine, if_exists = 'replace', chunksize=500, index=False, schema=\"dbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM under_performed_wells\"\n",
    "under_performed_wells_test = pd.read_sql(query,con)\n",
    "print(under_performed_wells_test.columns)\n",
    "under_performed_wells_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up5 = under_performed_wells_test.loc[under_performed_wells_test['percentile']<5].groupby('lease_no').agg('count') >= 84\n",
    "up5_wells = up5.iloc[[i for i, x in enumerate(up5.lat) if x]].index\n",
    "up5_wells_top50 = up5_wells[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM well_frac\"\n",
    "well_frac_test = pd.read_sql(query,con)\n",
    "print(well_frac_test.columns)\n",
    "well_frac_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dbo.adj_wells\"\n",
    "adj_wells_test = pd.read_sql(query,con)\n",
    "adj_wells_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up5_wells_top50_adj = adj_wells_test.loc[adj_wells_test['lease_no'].isin(up5_wells_top50)]\n",
    "up5_wells_top50_adj.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dbo.monthly_prod\"\n",
    "monthly_prod_test = pd.read_sql(query,con)\n",
    "monthly_prod_test.columns\n",
    "monthly_prod_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up5_top50_adj_prod = pd.merge(left = up5_wells_top50_adj, right = monthly_prod_test, left_on = 'adjacents', right_on = 'lease_no')\n",
    "up5_top50_adj_prod = up5_top50_adj_prod.drop('lease_no_y', axis=1)\n",
    "up5_top50_adj_prod = up5_top50_adj_prod.rename(columns={'lease_no_x':'lease_no'})\n",
    "up5_top50_adj_prod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_frac_adj = pd.merge(left = well_frac_test, right = adj_wells_test, left_on = 'LEASE_NO', right_on = 'adjacents')\n",
    "well_frac_adj = well_frac_adj[['lease_no', 'adjacents']].drop_duplicates()\n",
    "well_frac_adj.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push well_frac table to SQL server\n",
    "params = urllib.parse.quote_plus(r'DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "engine = create_engine(conn_str)\n",
    "up5_wells_top50_adj.to_sql(name='up5_wells_top50_adj',con=engine, if_exists = 'replace', chunksize=200, index=False, schema=\"dbo\")\n",
    "#up5_top50_adj_prod.to_sql(name='up5_top50_adj_prod',con=engine, if_exists = 'replace', chunksize=200, index=False, schema=\"dbo\")\n",
    "#well_frac_adj.to_sql(name='well_frac_adj',con=engine, if_exists = 'replace', chunksize=200, index=False, schema=\"dbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = random.randint(0, well_frac_adj.shape[0])\n",
    "print(well_frac_adj.iloc[ls])\n",
    "up5_frac = monthly_prod_test.loc[monthly_prod_test['lease_no'].isin(well_frac_adj.iloc[ls].values.tolist())]\n",
    "fig, ax = plt.subplots()\n",
    "for key, grp in up5_frac.groupby(['lease_no']):\n",
    "    ax = grp.plot(ax=ax, kind='line', x='date', y='monthly_prod', legend=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM prod_metrics\"\n",
    "prod_metrics_test = pd.read_sql(query,con)\n",
    "prod_metrics_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM well_locations\"\n",
    "locations_wells_test = pd.read_sql(query,con)\n",
    "locations_wells_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dbo.prod_norm\"\n",
    "prod_norm_test = pd.read_sql(query,con)\n",
    "print(prod_norm_test.dtypes)\n",
    "prod_norm_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dbo.prod_cumul\"\n",
    "prod_cumul_test = pd.read_sql(query,con)\n",
    "prod_cumul_test.dtypes\n",
    "prod_cumul_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM OG_COUNTY_LEASE_CYCLE\"\n",
    "OG_COUNTY_LEASE_CYCLE = pd.read_sql(query,con)\n",
    "print('OG_COUNTY_LEASE_CYCLE:',list(OG_COUNTY_LEASE_CYCLE.columns))\n",
    "OG_COUNTY_LEASE_CYCLE.head(5)\n",
    "plt.plot(OG_COUNTY_LEASE_CYCLE.CNTY_LSE_OIL_PROD_VOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT TOP 10 * FROM OG_COUNTY_LEASE_CYCLE_old\"\n",
    "OG_COUNTY_LEASE_CYCLE_old = pd.read_sql(query,con)\n",
    "print('OG_COUNTY_LEASE_CYCLE_old:',list(OG_COUNTY_LEASE_CYCLE_old.columns))\n",
    "OG_COUNTY_LEASE_CYCLE_old.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT TOP 10 * FROM Wellbore\"\n",
    "Wellbore = pd.read_sql(query,con)\n",
    "print('columns:',list(Wellbore.columns))\n",
    "Wellbore.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT TOP 100 * FROM FrackJobDates\"\n",
    "FrackJobDates = pd.read_sql(query,con)\n",
    "print('FrackJobDates:', list(FrackJobDates.columns))\n",
    "FrackJobDates.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT TOP 100 * FROM vFrackJobs\"\n",
    "vFrackJobs = pd.read_sql(query,con)\n",
    "print('vFrackJobs:', list(vFrackJobs.columns))\n",
    "vFrackJobs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM vFrackJobs INNER JOIN FrackingJobs_ProductionResults ON vFrackJobs.API = FrackingJobs_ProductionResults.API\"\n",
    "prod_frac = pd.read_sql(query,con)\n",
    "print('prod_frac:', list(prod_frac.columns))\n",
    "prod_frac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT TOP 100 * FROM FrackingJobs_ProductionResults\"\n",
    "FrackingJobs_PR = pd.read_sql(query,con)\n",
    "print('FrackingJobs_PR', list(FrackingJobs_PR.columns))\n",
    "FrackingJobs_PR.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FracFocus additional information about fracture jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob('./FracFocus/' + \"FracFocusRegistry_*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "fields = ['APINumber','JobStartDate', 'Latitude', 'Longitude', 'JobEndDate','Purpose','IngredientName']\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,usecols=fields, header=0)\n",
    "    list_.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm = pd.concat([i for i in list_], axis=0).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(frm.APINumber.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve under performed gas wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM dbo.well_metrics\"\n",
    "well_metrics_test = pd.read_sql(query,con)\n",
    "well_metrics_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = well_metrics_test[well_metrics_test['percentile']<5].groupby('lease_no').percentile.count() == 84\n",
    "up_wells = up[up.values == True].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fracking jobs only include info for ~6000 oil+gas wells, no info for the selected ~40,000 gas well that have records from 1994 to 2013.\n",
    "prod_frac.loc[prod_frac['LEASE_NO'].isin(well_metrics_test.lease_no)]\n",
    "len(list(prod_frac.LEASE_NO.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_wells_info = api_lease_locations.loc[api_lease.LEASE_NO.isin(up_wells)]\n",
    "up_wells_info.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Texas Land data: sparse las files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA (Envionment Protection Agency): cleaned FracFocus 1.0 voluntarily data from 2011 to 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QaWell = pd.read_csv('QaWell.csv')\n",
    "print('QaWell columns:', list(QaWell.columns))\n",
    "QaWell.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QaIngredient = pd.read_csv('QaIngredient.csv')\n",
    "print('QaIngredient columns:', list(QaIngredient.columns))\n",
    "QaIngredient.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_ingredient = pd.merge(left = QaWell, right=QaIngredient, on='WellId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_ingredient['API'] = well_ingredient['APIFFQA'].apply(lambda x: x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_lease_locations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_well_ingredient = pd.merge(left = api_lease_locations, right = well_ingredient, on = 'API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#53 APIs overlapped\n",
    "len(overlap_well_ingredient.API.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_frac = overlap_well_ingredient[['API', 'LEASE_NO', 'LatitudeFFQA', 'LongitudeFFQA', 'DateFFQA', 'TradeName', 'Purpose', 'ChemicalName', 'AdditiveConcentration', 'FluidConcentration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_frac.groupby('API').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push well_frac table to SQL server\n",
    "params = urllib.parse.quote_plus(r'DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "conn_str = 'mssql+pyodbc:///?odbc_connect={}'.format(params)\n",
    "engine = create_engine(conn_str)\n",
    "well_frac.to_sql(name='well_frac',con=engine, if_exists = 'append', chunksize=200, index=False, schema=\"dbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FracFocus APIs are different from RRC APIs: 16-18 digits vs 8-10 digits, distances were used to match with no luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm['API'] = frm['APINumber'].map(lambda x: str(x)[3:6] + '-' + str(x)[6:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of overlapped APIs RRC & FracFocus:', sum(frm['API'].isin(api_lease_locations.API)))\n",
    "print('# of overlapped APIs under-performed RRC & FracFocus:', sum(frm['API'].isin(up_wells_info.API)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APIs do not match between frm and up_wells_info\n",
    "frm_up = frm.loc[frm['API'].isin(up_wells_info.API), ['APINumber', 'API', 'Latitude', 'Longitude']]\n",
    "frm_up_info = frm_up.merge(up_wells_info, on='API')\n",
    "frm_up_info.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_wells_info.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm_api_locations = frm[['APINumber', 'Latitude', 'Longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm_api_locations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = 125\n",
    "a = up_wells_info[up_wells_info.LEASE_NO == ls]\n",
    "print(a.API)\n",
    "i = random.randint(0,(frm_api_locations.shape[0]))\n",
    "b = frm_api_locations.iloc[i]\n",
    "print(b.APINumber)  \n",
    "print((np.abs(a.WB_WGS84_LATITUDE - b.Latitude) < 1e-2))\n",
    "print((np.abs(-1*a.WB_WGS84_LONGITUDE - b.Longitude) < 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = 125\n",
    "a = up_wells_info[up_wells_info.LEASE_NO == ls]\n",
    "up_dst = {}\n",
    "dst_list = []\n",
    "for i in range(frm_api_locations.shape[0]):\n",
    "    b = frm_api_locations.iloc[i]\n",
    "    dst = np.linalg.norm(np.array(a.WB_WGS84_LATITUDE,-a.WB_WGS84_LONGITUDE)-np.array(b.Latitude,b.Longitude))\n",
    "    dst_list.append(dst)\n",
    "up_dst[ls] = dst_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frm_api_locations.iloc[np.array(up_dst[125]).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore tables for Power BI dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=40.124.30.130;DATABASE=TRC;UID=bpcs;PWD=319f0fa0f2ce18628E4a!')\n",
    "query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES\"\n",
    "#query = \"SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE='BASE TABLE'\"\n",
    "cursor = con.cursor()\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well_locaitons, well_metrics, prod_norm, prod_cumul, prod_metrics, monthly_prod, adj_wells, Well_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM monthly_prod\"\n",
    "monthly_prod = pd.read_sql(query,con)\n",
    "print(monthly_prod.columns)\n",
    "monthly_prod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM adj_wells\"\n",
    "adj_wells = pd.read_sql(query,con)\n",
    "print(adj_wells.columns)\n",
    "adj_wells.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_wells.loc[adj_wells['adjacents'] ==  127494, 'lease_no'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_131086 = adj_wells.loc[adj_wells['adjacents'] ==  131086, 'lease_no'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM well_frac\"\n",
    "well_frac = pd.read_sql(query,con)\n",
    "print(well_frac.columns)\n",
    "well_frac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_prod_frac = pd.merge(left = well_frac, right = monthly_prod, left_on = 'LEASE_NO', right_on = 'lease_no')\n",
    "monthly_prod_frac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_list = monthly_prod_frac.LEASE_NO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = random.randint(0, len(frac_list))\n",
    "print(frac_list[ls])\n",
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == frac_list[ls], ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 143739(x), 131086, 127494, 134419(x), 136145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = random.randint(0, len(adj_131086))\n",
    "print(adj_131086[ls])\n",
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == adj_131086[ls], ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == 134419, ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == 136145, ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == 127494, ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == 143739, ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = monthly_prod_frac.loc[monthly_prod_frac['LEASE_NO'] == 131086, ['date','monthly_prod', 'DateFFQA']]\n",
    "if len(prod.monthly_prod.value_counts()) > 0:\n",
    "    prod.plot(x='date',y='monthly_prod',marker='.',linestyle='None')\n",
    "print(prod.DateFFQA.unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
